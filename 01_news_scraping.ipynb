{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "384d95bc",
   "metadata": {},
   "source": [
    "1 Daum 뉴스기사 제목 스크래핑하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22ba5ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://news.daum.net/economy\n",
      "<class 'requests.models.Response'>\n",
      "200\n",
      "<class 'bs4.element.ResultSet'> 9\n",
      "https://v.daum.net/v/20250409100338422\n",
      "기름 넣을 때마다 내는 세금, 적절한 곳에 쓰고 있나요? [질문+]\n",
      "https://v.daum.net/v/20250409100040256\n",
      "'원금지급·초과수익' 첫 IMA 연내지정…한국판 골드만삭스 시동\n",
      "https://v.daum.net/v/20250409100011190\n",
      "'원금지급' IMA 제도, 8년 만에 구체화…하반기에 8조 종투사 지정\n",
      "https://v.daum.net/v/20250409095612972\n",
      "회사는 주주만의 것? 상법 개정이 품은 위험\n",
      "https://v.daum.net/v/20250409095604965\n",
      "발의자가 설명하는 ‘상법 왜 바꿨나’\n",
      "https://v.daum.net/v/20250409095558958\n",
      "K밸류업 외치는 사이, 무너지는 한국 제조업\n",
      "https://v.daum.net/v/20250409095110733\n",
      "[친절한 경제] 초고령 사회 진입…'정년 연장'보다 필요한 근로 형태는?\n",
      "https://v.daum.net/v/20250409094730569\n",
      "3월 취업자 19.3만 늘었지만…청년·건설·제조업 '고용한파' 지속(종합)\n",
      "https://v.daum.net/v/20250409091935326\n",
      "‘회복’이라는 착시.. “청년은 떠났고, 일터는 비어 있다”\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 다음 경제 뉴스 URL\n",
    "url = 'https://news.daum.net/economy'\n",
    "\n",
    "print(url)\n",
    "\n",
    "# 요청 헤더\n",
    "req_header = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "res = requests.get(url, headers=req_header)\n",
    "print(type(res))\n",
    "print(res.status_code)\n",
    "\n",
    "# 정상 응답 여부 확인\n",
    "if res.ok:\n",
    "    res.encoding = 'utf-8' \n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    # 기사 제목과 링크 추출\n",
    "    # [<li></li>,<li></li>]\n",
    "    li_tag_list = soup.select('ul.list_newsheadline2 li')\n",
    "\n",
    "    print(type(li_tag_list), len(li_tag_list))\n",
    "\n",
    "    for li_tag in li_tag_list:        \n",
    "        a_tag = li_tag.find('a')\n",
    "        print(a_tag['href'])\n",
    "        \n",
    "        # select() => ResultSet, select_one() => Tag\n",
    "        strong_tags = li_tag.select('div.cont_thumb strong.tit_txt')\n",
    "        if strong_tags:\n",
    "            strong_tag = strong_tags[0]\n",
    "        #strong_tag = li_tag.select_one('div.cont_thumb strong.tit_txt')\n",
    "        title = strong_tag.text.strip()\n",
    "        print(title)\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f'에러코드 = {res.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d8b622d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'기후/환경': 'climate',\n",
       " '사회': 'society',\n",
       " '경제': 'economy',\n",
       " '정치': 'politics',\n",
       " '국제': 'world',\n",
       " '문화': 'culture',\n",
       " '생활': 'life',\n",
       " 'IT/과학': 'tech',\n",
       " '인물': 'people'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_dict = {'기후/환경':'climate','사회':'society','경제':'economy','정치':'politics',\\\n",
    "                '국제':'world','문화':'culture','생활':'life','IT/과학':'tech','인물':'people'}\n",
    "section_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8192c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def print_news(section_name):    \n",
    "    #section = section_dict[section_name]\n",
    "    section = section_dict.get(section_name)\n",
    "    if section is None:\n",
    "        print('요청하신 Key가 없습니다.')\n",
    "    else:    \n",
    "        # 요청 Parameter\n",
    "        req_param = {\n",
    "            'section': section\n",
    "        }\n",
    "        url = 'https://news.daum.net/{section}'.format(**req_param)\n",
    "        \n",
    "        print(f'======> {url} {section_name} 뉴스 <======')\n",
    "        \n",
    "        # 요청 헤더 설정 : 브라우저 정보\n",
    "        req_header = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/104.0.0.0 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        res = requests.get(url, headers=req_header)   \n",
    "\n",
    "        if res.ok:\n",
    "            res.encoding = 'utf-8' \n",
    "            html = res.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # 기사 제목과 링크 추출\n",
    "            li_tag_list = soup.select('ul.list_newsheadline2 li')\n",
    "\n",
    "            #print(type(li_tag_list), len(li_tag_list))\n",
    "\n",
    "            for li_tag in li_tag_list:        \n",
    "                a_tag = li_tag.find('a')\n",
    "                print(a_tag['href'])\n",
    "                \n",
    "                strong_tag = li_tag.select_one('div.cont_thumb strong.tit_txt')\n",
    "                title = strong_tag.text.strip()\n",
    "                print(title)\n",
    "\n",
    "        else:\n",
    "            print(f'에러코드 = {res.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfd12c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> https://news.daum.net/economy 경제 뉴스 <======\n",
      "https://v.daum.net/v/20250409095612972\n",
      "회사는 주주만의 것? 상법 개정이 품은 위험\n",
      "https://v.daum.net/v/20250409095604965\n",
      "발의자가 설명하는 ‘상법 왜 바꿨나’\n",
      "https://v.daum.net/v/20250409095558958\n",
      "K밸류업 외치는 사이, 무너지는 한국 제조업\n",
      "https://v.daum.net/v/20250409095110733\n",
      "[친절한 경제] 초고령 사회 진입…'정년 연장'보다 필요한 근로 형태는?\n",
      "https://v.daum.net/v/20250409094730569\n",
      "3월 취업자 19.3만 늘었지만…청년·건설·제조업 '고용한파' 지속(종합)\n",
      "https://v.daum.net/v/20250409093301936\n",
      "투심 끊긴 CBD 오피스…\"이 값엔 못 팔아\" 잇단 매각 철회도\n",
      "https://v.daum.net/v/20250409091935326\n",
      "‘회복’이라는 착시.. “청년은 떠났고, 일터는 비어 있다”\n",
      "https://v.daum.net/v/20250409091646199\n",
      "[뉴스UP] 미국, 오늘부터 25% 상호관세...뭐가 어떻게 바뀌나?\n",
      "https://v.daum.net/v/20250409081220033\n",
      "[美 관세대응]수출바우처 1000억·긴급경영자금 2500억…남미로 수출다변화\n"
     ]
    }
   ],
   "source": [
    "print_news('경제2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba61962",
   "metadata": {},
   "source": [
    "2-1. Nate 뉴스기사 제목 스크래핑하기 (필수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe14e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writhing to 20250409182110314001.jpg(2,539 bytes) \n",
      "Writhing to ae_1744182726915_812413_0.jpg(3,027 bytes) \n",
      "Writhing to 20250318517251.jpg(1,941 bytes) \n",
      "[단독] 이완규, 경찰에 \"알 바 아냐\"…안가 회동 묻자 위압적 태도\t\t\t\t\t[앵커]오늘(9일) 나란히 국회에 나온 오동운 공수처장은 이완규 처장을 '수사 대상'이라고 못 박았습니다. 경찰에서는 이미 '삼청동 안가 회동'으로 피의자 조사...\n",
      "https://news.nate.com/view/20250409n37357?mid=n0200\n",
      "오세훈 13일 대선 출사표…\"죄송한 마음에 결심 늦었다\"(종합)\t\t\t\t\t오세훈 서울시장이 오는 13일 대선 출마를 공식 선언한다. 오 시장은 올해 초부터 규제철폐, 경제 성장 등 굵직한 정책 아이디어를 쏟아내며 대권주자로서의 존...\n",
      "https://news.nate.com/view/20250409n29780?mid=n0200\n",
      "검찰, '명태균 처남 채용 의혹' 경남평생교육진흥원 압수수색\t\t\t\t\t검찰이 '정치 브로커' 명태균씨 처남 채용 청탁 의혹과 관련해 명씨 처남이 근무하고 있는 경남도인재평생교육진흥원을 압수수색했다. 9일 법조계 등에 따르면 ...\n",
      "https://news.nate.com/view/20250409n34600?mid=n0200\n",
      "[단독]경호처, '윤석열 체포 저지' 반대 간부 해임징계 한덕수에 제청\t\t\t\t\t한덕수 권한대행 승인하면 해임 확정, 간부 측 반발김성훈 대통령 경호처 차장이 지난 1월17일 오전 서울 서대문구 경찰청 국가수사본부에서 비상계엄 특별수사...\n",
      "https://news.nate.com/view/20250409n33483?mid=n0200\n",
      "'훈련병 사망' 중대장·부중대장, 항소심서도 무죄 주장\t\t\t\t\t얼차려 지시로 훈련병 사망하게 한 중대장.(뉴스1 DB) (춘천=뉴스1) 한귀섭 기자 = 육군 신병교육대에서 규정을 어긴 군기 훈련(얼차려)으로 훈련병을 숨지게 한...\n",
      "https://news.nate.com/view/20250409n30984?mid=n0200\n",
      "권성동 \"윤석열·이재명 동시 퇴장이 시대의 명령\"\t\t\t\t\t사진=뉴스1권성동 국민의힘 원내대표는 윤석열 전 대통령과 이재명 전 더불어민주당 대표의 동시 퇴장이 '시대의 명령'이라고 주장했다.권 원내대표는 9일 국회...\n",
      "https://news.nate.com/view/20250409n27024?mid=n0200\n",
      "'대선 시동' 이재명, 8년 만의 단독 저서 '결국 국민이 합니다' 출간\t\t\t\t\t9일 대표직을 내려놓은 이재명 전 더불어민주당 대표가 새 책을 출간했다. [오마이북 제공] [헤럴드경제=문혜현 기자] 9일 더불어민주당 대표직을 사퇴한 이재명...\n",
      "https://news.nate.com/view/20250409n22374?mid=n0200\n",
      "우원식 \"인사청문 요청 접수 않겠다\"…법조계 보이콧엔 회의적\t\t\t\t\t한덕수 대통령 권한대행 겸 국무총리(왼쪽)가 15일 서울 여의도 국회에서 우원식 의장을 예방, 모두 발언하고 있다. 2024.12.15/뉴스1 ⓒ News1 안은나 기자 (서...\n",
      "https://news.nate.com/view/20250409n26089?mid=n0200\n",
      "국힘 대선 후보군 벌써 15명…'절대 강자' 없자 너도나도 \"출마\"\t\t\t\t\t9일 서울 여의도 국회에서 열린 국민의힘 선거관리위원회의에서 황우여 선관위원장 등 참석자들이 기념촬영을 하고 있다. 연합뉴스 국민의힘 대선 후보 경선이 ...\n",
      "https://news.nate.com/view/20250409n23624?mid=n0200\n",
      "이철우 \"이재명 이길 새 인물…새로운 박정희 되겠다\"\t\t\t\t\t9일 국회에서 21대 대선 출마 선언 이철우 경북지사가 9일 오후 서울 여의도 국회 소통관에서 제21대 대통령선거 출마 선언 기자회견을 하고 있다. 뉴스1 [파이...\n",
      "https://news.nate.com/view/20250409n23037?mid=n0200\n",
      "김두관 \"국회 분원·대통령실 부지 있는 세종…수도 이전 충분히 가능\"\t\t\t\t\t2003년 행정수도 추진 당시 행자부 장관\"헌재, '관습 헌법' 들었지만 시대 달라져\"\"부지·예산 모두 갖춰...이번엔 동의할 것\"6·3 대선 출마를 선언한 김두관 ...\n",
      "https://news.nate.com/view/20250409n16582?mid=n0200\n",
      "김문수 \"위대한 대한민국 이룰 것\"…현충원 찾아 본격 대선 모드\t\t\t\t\t김문수 전 고용노동부 장관이 9일 서울 동작구 국립서울현충원을 찾아 현충탑 참배 후 방명록을 작성하고 있다. 이날 김 전 장관은 현충원 참배 직전 국회를 찾...\n",
      "https://news.nate.com/view/20250409n21665?mid=n0200\n",
      "김동연이 밝힌 '3무3유 선거운동'…\"국민이 계파이고 조직\"\t\t\t\t\t수원=박성훈 기자 김동연 경기지사는 9일 인천국제공항에서 대통령 선거 출마를 공식 선언하면서 \"이번 대선에서 ‘3무(無) 3유(有)’ 선거운동으로 바람을 일으...\n",
      "https://news.nate.com/view/20250409n21326?mid=n0200\n",
      "'막차' 타고 대구 간 이준석…\"이재명 대권 목전…이기는 선택 되겠다\"\t\t\t\t\t[the300] \"지난 대선, 광주 복합쇼핑몰 성과…대구에서도 그런 과제 풀어야\" 이준석 개혁신당 대선 후보. /사진=개혁신당. 이준석 개혁신당 대선(대통령선거) 후...\n",
      "https://news.nate.com/view/20250409n20281?mid=n0200\n",
      "황교안, 국힘 탈당 대선 출마 \"부정선거 척결…尹 응원 받아\"\t\t\t\t\t황교안 전 국무총리가 9일 오전 서울 용산구에 위치한'황교안 비전캠프'에서 국민의힘 탈당과 함께 무소속으로 대선 출마를 선언하고 있다. (황교안 비전캠프 제...\n",
      "https://news.nate.com/view/20250409n19177?mid=n0200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# IT/과학 뉴스 \n",
    "req_param = {\n",
    "    'sid': 'section?mid=n0200'\n",
    "}\n",
    "\n",
    "url = 'https://news.nate.com/{sid}'.format(**req_param)\n",
    "\n",
    "# 요청 헤더 설정 : 브라우저 정보(사람처럼 보이게 하려고 설정하는 것임임)\n",
    "req_header = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "img_urls = [\n",
    "    'https://thumbnews.nateimg.co.kr/news90///news.nateimg.co.kr/orgImg/jt/2025/04/09/20250409182110314001.jpg',\n",
    "    'https://thumbnews.nateimg.co.kr/news90///news.nateimg.co.kr/orgImg/ae/2025/04/09/ae_1744182726915_812413_0.jpg',\n",
    "    'https://thumbnews.nateimg.co.kr/news90///news.nateimg.co.kr/orgImg/sg/2025/04/09/20250318517251.jpg'\n",
    "]\n",
    "\n",
    "for img_url in img_urls:\n",
    "    # requests 의 get(url, headers) 함수 호출하기 \n",
    "    res = requests.get(img_url, headers=req_header)\n",
    "    if res.ok:\n",
    "        # binary 응답 데이터 가져오기 content라는 프로퍼티 사용\n",
    "        img_data = res.content\n",
    "        # url에서 파일명만 추출하기\n",
    "        file_name = os.path.basename(img_url)\n",
    "        # binday data를 file에 write하기\n",
    "        with open(file_name, 'wb') as file:\n",
    "            print(f'Writhing to {file_name}({len(img_data):,} bytes) ')\n",
    "            file.write(img_data)\n",
    "\n",
    "# requests 의 get() 함수 호출하기 \n",
    "res = requests.get(url, headers=req_header)\n",
    "\n",
    "# 응답(response)이 OK 이면\n",
    "if res.ok:\n",
    "    # 응답 (response)에서 text 추출 - surce 보기\n",
    "    html = res.text\n",
    "    # BeautifulSoup 객체 생성  \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    img_tags = soup.select(\"img[src*='orgImg']\")\n",
    "    img_url_list = list()\n",
    "    for img_tag in img_tags:\n",
    "        #print(type(img_tag), img_tag.name, img_tag)\n",
    "        img_src = img_tag['src']\n",
    "        img_url_list.append(img_src)\n",
    "        \n",
    "    imgdir_name = 'img'\n",
    "    if not os.path.isdir(imgdir_name):\n",
    "        os.mkdir(imgdir_name)\n",
    "          \n",
    "    #print(soup)\n",
    "    # CSS 선택자\n",
    "    # <div class='sa_text'><a href=''></a></div>에 mnews/article라는 말이 들어간 것을 찾아라\n",
    "    a_tag_list = soup.select(\"div.mlt01 a[href*='mid=n0200']\")\n",
    "    \n",
    "    for a_tag in a_tag_list:\n",
    "        # print(type(a_tag))\n",
    "        title = a_tag.text.strip()\n",
    "        \n",
    "        # href 속성의 값 가져오기\n",
    "        link = 'https:' + a_tag['href']\n",
    "        \n",
    "        print(title)\n",
    "        print(link)\n",
    "\n",
    "    # <a> 태그 리스트 순회하기    \n",
    "else:    \n",
    "    # 응답(response)이 Error 이면 status code 출력    \n",
    "    print(f'에러 코드 = {res.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "766da440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'section?mid=n0100': '최신뉴스',\n",
       " 'section?mid=n0200': '정치',\n",
       " 'section?mid=n0300': '경제',\n",
       " 'section?mid=n0400': '사회',\n",
       " 'section?mid=n0500': '세계',\n",
       " 'section?mid=n0600': 'IT/과학'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_dict = {'section?mid=n0100':'최신뉴스','section?mid=n0200':'정치','section?mid=n0300':'경제','section?mid=n0400':'사회',\\\n",
    "                'section?mid=n0500':'세계','section?mid=n0600':'IT/과학'}\n",
    "section_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def print_news(section_name):    \n",
    "    #section = section_dict[section_name]\n",
    "    section = section_dict.get(section_name)\n",
    "    \n",
    "    if section is None:\n",
    "        print('요청하신 Key가 없습니다.')\n",
    "    else:    \n",
    "        # 요청 Parameter\n",
    "        req_param = {\n",
    "            'section': section\n",
    "        }\n",
    "        url = 'https://news.nate.com/{section}'.format(**req_param)\n",
    "        \n",
    "        # 요청 헤더 설정 : 브라우저 정보\n",
    "        req_header = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36'\n",
    "        }\n",
    "\n",
    "        res = requests.get(url, headers=req_header)   \n",
    "\n",
    "        if res.ok:\n",
    "            res.encoding = 'utf-8' \n",
    "            html = res.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            \n",
    "            # 기사 제목과 링크 추출\n",
    "            a_tag_list = soup.select(\"div.mlt01 a[href*='?mid=n0200']\")\n",
    "            print(a_tag_list)\n",
    "\n",
    "            #print(type(li_tag_list), len(li_tag_list))\n",
    "\n",
    "            for a_tag in a_tag_list:\n",
    "                 \n",
    "                a_tag = li_tag.find('a')\n",
    "                title = a_tag.text.strip()\n",
    "                # href 속성의 값 가져오기\n",
    "                link = a_tag['href']\n",
    "                print(title)\n",
    "\n",
    "        else:\n",
    "            print(f'에러코드 = {res.status_code}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2b2863e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ddddd\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print_news('section?mid=n0200')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19db55a",
   "metadata": {},
   "source": [
    "2-2. 하나의 네이버 웹툰과 1개의 회차에 대한 Image 다운로드 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3da4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "req_header = {\n",
    "    'referer': 'https://comic.naver.com/webtoon/detail?titleId=823195&no=108&week=wed'\n",
    "}\n",
    "\n",
    "img_urls = [\n",
    "    'https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_1.jpg',\n",
    "    'https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_2.jpg',\n",
    "    'https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_3.jpg'\n",
    "]\n",
    "\n",
    "for img_url in img_urls:\n",
    "    # requests 의 get(url, headers) 함수 호출하기 \n",
    "    res = requests.get(img_url, headers=req_header)\n",
    "    if res.ok:\n",
    "        # binary 응답 데이터 가져오기 content라는 프로퍼티 사용\n",
    "        img_data = res.content\n",
    "        # url에서 파일명만 추출하기\n",
    "        file_name = os.path.basename(img_url)\n",
    "        # binday data를 file에 write하기\n",
    "        with open(file_name, 'wb') as file:\n",
    "            print(f'Writhing to {file_name}({len(img_data):,} bytes) ')\n",
    "            file.write(img_data)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a0cf594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_1.jpg', 'https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_10.jpg']\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_1.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_10.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_11.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_12.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_13.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_14.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_15.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_16.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_17.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_18.jpg\n",
      "'쌉초의 난', 108, https://image-comic.pstatic.net/webtoon/823195/108/20250408180001_241c480040c374e4035a04fdd4f0b2c1_IMAG01_19.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "url = 'https://comic.naver.com/webtoon/detail?titleId=823195&no=108&week=wed'\n",
    "req_header = {\n",
    "    'referer': url\n",
    "}\n",
    "res = requests.get(url)\n",
    "\n",
    "title = '쌉초의 난'\n",
    "if res.ok:\n",
    "    # jpg 파일의 절대경로 url를 찾기\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    \n",
    "    img_tags = soup.select(\"img[src*='IMAG01_1']\")\n",
    "    # img src 를 저장할 list 선언\n",
    "    img_url_list = list() # ['aa.jpg','aa1.jpg']\n",
    "    for img_tag in img_tags:\n",
    "        img_src = img_tag['src']\n",
    "        img_url_list.append(img_src)\n",
    "    \n",
    "    #img 디렉토리가 없으면 생성하기   \n",
    "    imgdir_name = 'img'\n",
    "    if not os.path.isdir(imgdir_name):\n",
    "        os.mkdir(imgdir_name)\n",
    "        \n",
    "    #os.path.join(dir,file) 함수 사용하여 디렉토리명과 파일명 합치기\n",
    "    for img_url in img_url_list:\n",
    "        res = requests.get(img_url, headers=req_header)\n",
    "        if res.ok:        \n",
    "            # binary data 가져오기\n",
    "            img_data = res.content\n",
    "            # img/xxx.jpg 디렉토리명과 파일명을 join\n",
    "            dir_name = os.path.join(imgdir_name, os.path.basename(img_url))\n",
    "            # binday data를 file에 write하기\n",
    "            with open(dir_name,'wb') as file:\n",
    "                print(f\"'{title}', 108, {img_url}\")\n",
    "                file.write(img_data)\n",
    "        else:\n",
    "            print(f'Error Code = {res.status_code}')      \n",
    "            \n",
    "else:\n",
    "    print(f'Error Code = {res.status_code}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
